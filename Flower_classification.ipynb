{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n",
      "0.0 0.99618727\n",
      "Epoch 1/10\n",
      "92/92 [==============================] - 93s 1s/step - loss: 1.3582 - accuracy: 0.4179 - val_loss: 1.0852 - val_accuracy: 0.5681\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 85s 923ms/step - loss: 1.0199 - accuracy: 0.6018 - val_loss: 1.0079 - val_accuracy: 0.5995\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 91s 986ms/step - loss: 0.8321 - accuracy: 0.6802 - val_loss: 1.0039 - val_accuracy: 0.6104\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 94s 1s/step - loss: 0.6280 - accuracy: 0.7759 - val_loss: 0.8584 - val_accuracy: 0.6689\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 88s 955ms/step - loss: 0.4669 - accuracy: 0.8314 - val_loss: 0.9371 - val_accuracy: 0.6635\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 86s 939ms/step - loss: 0.2797 - accuracy: 0.9091 - val_loss: 1.1399 - val_accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 86s 939ms/step - loss: 0.1552 - accuracy: 0.9482 - val_loss: 1.4035 - val_accuracy: 0.6281\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 88s 952ms/step - loss: 0.1089 - accuracy: 0.9666 - val_loss: 1.5768 - val_accuracy: 0.6362\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 87s 942ms/step - loss: 0.0799 - accuracy: 0.9789 - val_loss: 1.7684 - val_accuracy: 0.6335\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 86s 939ms/step - loss: 0.0435 - accuracy: 0.9874 - val_loss: 1.7774 - val_accuracy: 0.6471\n",
      "Saving Model:\n",
      "WARNING:tensorflow:From C:\\Users\\HSD\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\HSD\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: My_trained_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "\n",
    "#Load using keras.preprocessing\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) \n",
    "\n",
    "# Create the model\n",
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "#compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "#Train the model\n",
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")\n",
    "print(\"Saving Model:\")\n",
    "model.save('My_trained_model/my_model') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to roses with a 99.42 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    'd1.jpg', target_size=(img_height, img_width)\n",
    ")\n",
    "\n",
    "# convert image to tensor or numpy\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
